{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a7c89c",
   "metadata": {},
   "source": [
    "# Statistics/Econometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a84e4",
   "metadata": {},
   "source": [
    "This notebook has a focus on statistics and econometrics. Following the youtube series here by Ben Lambert:\n",
    " - [A full course in econometrics - undergraduate level - part 1](https://www.youtube.com/playlist?list=PLwJRxp3blEvZyQBTTOMFRP_TDaSdly3gU)\n",
    " - [A full course in econometrics - undergraduate level - part 2](https://www.youtube.com/playlist?list=PLwJRxp3blEvb7P-7po9AxuBwquPv75LjU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928eddf5",
   "metadata": {},
   "source": [
    "## Super summary\n",
    "\n",
    "\n",
    "**Esitamtors**\n",
    " - We estimate population parameters $\\beta^p$ using sample estimates $\\hat\\beta$. We want these estimates to be\n",
    "     - Unbiased $\\mathbb{E}(\\beta_i) = \\beta^p$\n",
    "     - Consistent $\\lim_{n \\to \\infty} \\beta_n = \\beta_p$\n",
    "     - Efficient (close to the true value)\n",
    "     - Ideally linear in parameters\n",
    "\n",
    "**Least squares estiamtion**\n",
    " - For a population process which connects an output variable (dependent variable) with an independent variable we can model with a linear model (line of best fit) $\\hat{y}=\\hat{\\beta}X+\\hat{\\alpha}$.\n",
    " - In least squares we find the parameters to minimise $S = \\sum_{i=1}^N(y_i - \\hat{y}_i)^2$\n",
    " - Such that $\\hat{\\beta} = \\frac{\\sum_{i=1}^N(x_i-\\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^N(x_i - \\bar{x})^2} = \\frac{Cov(x_i, y_i)}{Var(x_i)}$ and  $\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}$\n",
    " \n",
    "**Expectation, moments, variance, kurtosis, skewness**\n",
    " - We define the expectation of a random variable $\\mathbb{E}[X] = \\int_{-\\inf}^{\\inf}f_y(x)x\\,dx$\n",
    " - We define the kth moment of X as $\\mathbb{E}[X^k] = \\int_{-\\inf}^{\\inf}f_x(x)x^k\\,dx$\n",
    " - $\\mathbb{E}[(X-\\bar{X})^2]$ is known as the 2nd central moment or more commonly the variance.\n",
    " - The kurtosis is defined as the 4th standardised moment $Kurt[X] = \\mathbb{E}[(\\frac{X-\\bar{X}}{\\sigma})^4]$. Large Kurtosis indicates fat tails and vice versa.\n",
    " - Skewness is the third central moment $\\mathbb{E}[(X-\\bar{X})^3]$\\\n",
    " - $\\mathbb{E}[aX + bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]$\n",
    " - $\\text{Var}(aX + bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y) + 2ab\\,\\text{Cov}(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62382862",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1204cd8",
   "metadata": {},
   "source": [
    "### Video 1 - Undergraduate econometrics syllabus\n",
    "\n",
    "Summary of course\n",
    "\n",
    " - Estimating population parameters from sample (using estimators)\n",
    " - Cross sectional data (no time element)\n",
    " - OLS (ordinary least squares) is BLUE (best linear unbiased estimator) under gauss markoff conditions\n",
    " - Consistency\n",
    " - Instrumental variables\n",
    " - GLS\n",
    " - Time series\n",
    " - Stationary time series\n",
    " - Auto regressive (1)\n",
    " - Moving average (1)\n",
    " - Panel Data\n",
    " - Data generating process\n",
    " - Between estimator\n",
    " - Withing estimator\n",
    " - Fixed/Random effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfb755",
   "metadata": {},
   "source": [
    "### Video 2 - What is econometrics\n",
    "\n",
    " - Econometrics helps to explain relationships (e.g. TV ad spend and sales)\n",
    " - Estimating Population parameters from samples (sampling error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e276336",
   "metadata": {},
   "source": [
    "### Video 3 - Econometrics vs hard science\n",
    "\n",
    " - Can't always use a controlled test (AB test)\n",
    " - Issues with reverse-causal effects (y actually causes x, or confounding variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae95b10",
   "metadata": {},
   "source": [
    "### Video 4 - Natural experiments in econometrics\n",
    "\n",
    " - An experiment that resulted due to another action e.g. army conscription by birth date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63cc3d7",
   "metadata": {},
   "source": [
    "### Video 5 - Populations and samples in Economics\n",
    "\n",
    " - Examples of a population - e.g. UK under 18s\n",
    " - We often want to understand relationships e.g. impact of years of education on wages $W=\\alpha + \\beta E$\n",
    " - We often only have data for a sample\n",
    " - When estimating parameters from a sample this parameter will differ from the population parameter and we call this sampling error $\\beta_s\\neq\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f61db",
   "metadata": {},
   "source": [
    "### Video 6 - Estimators - the basics\n",
    "\n",
    " - Effect of years of education on wages $W=\\alpha + \\beta E$ in UK under 18s.\n",
    " - Let's say we only have 1000 in our sample we want to make an estimator $\\hat\\beta$ of the population parameter $\\beta^\\star$ from the sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3807fbc",
   "metadata": {},
   "source": [
    "### Video 7- Estimator properties\n",
    "\n",
    " - What does it mean to be a good estimator?\n",
    " - If we take many samples $S_1, S_2, S_3, ...$ from the population and calculate estimators $\\beta_1, \\beta_2, \\beta_3, ...$ from the samples using our estimator formula.\n",
    " - We want the expectation of the estimates to be equal to the population parameter $\\mathbb{E}(\\beta_i) = \\beta^p$. This is known as an **Unbiased estimator**\n",
    " - We also want our estimate to tend to the population parameter as the sample size n increases $\\lim_{n \\to \\infty} \\beta_n = \\beta_p$. This is known as a **Consistent estimator**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e22cde",
   "metadata": {},
   "source": [
    "### Video 8 - Unbiasedness and consistency\n",
    "\n",
    " - It is possible to have a bias consistent estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51df3e1",
   "metadata": {},
   "source": [
    "### Video 9 - Unbiasedness vs consistency of estimators - an example\n",
    "\n",
    " - An example of a consistent but bias estimator is using $\\hat{\\mu}=\\frac{1}{N-1}\\sum{X_i}$ to estimate the population mean from a sample $X_1, X_2, X_3, ...$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc046990",
   "metadata": {},
   "source": [
    "### Video 10 - Efficiency of estimators\n",
    "\n",
    " - The efficiency of an estimator $\\tilde\\beta$ relates to how close the estimate will be for a given sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9bb74",
   "metadata": {},
   "source": [
    "### Video 11 - Good estimator properties summary\n",
    "\n",
    " - Unbiased, consistent, efficient and linear in parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627267f2",
   "metadata": {},
   "source": [
    "### Video 12 - Lines of best fit in econometrics\n",
    "\n",
    " - Looking at the example of the impact of education, X on wages, Y. We can write the relationship for the population as $Y = \\beta^PX + \\alpha$. We can do similar for a sample $Y = \\beta^SX + \\alpha$. We are using $\\beta^S$ to estimate $\\beta^P$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb2de1",
   "metadata": {},
   "source": [
    "### Video 13 - The mathematics behind a line of best fit\n",
    "\n",
    " - Again we are modeling the situation $Y = \\hat{\\beta}X + \\hat{\\alpha}$\n",
    " - We can minimise the sum of abs errors $S = \\sum_{i=1}^N|y_i - \\hat{y}_i|$\n",
    " - We can also minimise the sum of the square of the errors $S = \\sum_{i=1}^N(y_i - \\hat{y}_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b992d",
   "metadata": {},
   "source": [
    "### Video 14 - Least squares Estimators as Blue\n",
    "\n",
    " - We want an estimate to be Unbiased, consistent and efficient\n",
    " - BLUE - Best Linear Unbiased Estimator\n",
    " - Best means there are no other linear estimators that are more efficient\n",
    " - Under the Gauss Markov assumptions least squares estimators are BLUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c280159",
   "metadata": {},
   "source": [
    "### Video 15 - Deriving Least Squares Estimators - part 1\n",
    "\n",
    " - Deriving $\\hat{\\alpha}$ and $\\hat{\\beta}$ where $\\hat{y}=\\hat{\\beta}X+\\hat{\\alpha}$ to minimise $S = \\sum_{i=1}^N(y_i - \\hat{y}_i)^2$\n",
    " - To solve this we want $\\frac{\\partial S}{\\partial \\hat{\\alpha}} = 0, \\frac{\\partial S}{\\partial \\hat{\\beta}} = 0$\n",
    " - We can write S as $S = \\sum_{i=1}^N(y_i - \\hat{\\beta}x_i+\\hat{\\alpha})^2$ so then we have the following conditions\n",
    " - $\\frac{\\partial S}{\\partial \\hat{\\alpha}} = -2\\sum_{i=1}^N(y_i - \\hat{\\beta}x_i+\\hat{\\alpha}) = 0$\n",
    " - $\\frac{\\partial S}{\\partial \\hat{\\beta}} = -2\\sum_{i=1}^Nx_i(y_i - \\hat{\\beta}x_i+\\hat{\\alpha}) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca471b05",
   "metadata": {},
   "source": [
    "### Video 16 - Deriving Least Squares Estimators - part 2\n",
    "\n",
    " - Note based on the definition of the mean we can write: $\\sum_{i=1}^Nx_i=N\\bar{x}$ and  $\\sum_{i=1}^Ny_i=N\\bar{y}$\n",
    " - Also note $\\sum_{i=1}^N(x_i - \\bar{x})(y_i - \\bar{y}) = \\sum_{i=1}^Ny_i(x_i - \\bar{x}) = \\sum_{i=1}^Nx_i(y_i - \\bar{y})$\n",
    " Proof:\n",
    " $$\\sum_{i=1}^N(x_i - \\bar{x})(y_i - \\bar{y}) \\\\\n",
    "  = \\sum_{i=1}^N(x_iy_i - x_i\\bar{y} - \\bar{x}y_i + \\bar{x}\\bar{y}) \\\\\n",
    "  = \\sum_{i=1}^Nx_iy_i - \\bar{y}\\sum_{i=1}^Nx_i - \\bar{x}\\sum_{i=1}^Ny_i + N\\bar{x}\\bar{y} \\\\\n",
    "  = \\sum_{i=1}^Nx_iy_i - \\bar{y}N\\bar{x} - \\bar{x}N\\bar{y} + N\\bar{x}\\bar{y} \\\\\n",
    "  = \\sum_{i=1}^Nx_iy_i - N\\bar{x}\\bar{y} \\\\\n",
    "  = \\sum_{i=1}^Nx_iy_i - \\bar{x}\\sum_{i=1}^Ny_i \\\\\n",
    "  = \\sum_{i=1}^Ny_i(x_i - \\bar{x}) \\\\\n",
    " $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fc3da",
   "metadata": {},
   "source": [
    "### Video 17 - Deriving Least Squares Estimators - part 3\n",
    "\n",
    " - Two videos ago we differentiated S to get the following conditions:\n",
    " - $\\frac{\\partial S}{\\partial \\hat{\\alpha}} = -2\\sum_{i=1}^N(y_i - \\hat{\\beta}x_i+\\hat{\\alpha}) = 0$ (1)\n",
    " - $\\frac{\\partial S}{\\partial \\hat{\\beta}} = -2\\sum_{i=1}^Nx_i(y_i - \\hat{\\beta}x_i+\\hat{\\alpha}) = 0$ (2)\n",
    " - Using (1) $\\sum_{i=1}^Ny_i = N\\hat{\\alpha} + \\hat{\\beta}\\sum_{i=1}^Nx_i$\n",
    " - hence $N\\bar{y} = \\hat{\\alpha}N + \\hat{\\beta}N\\bar{x}$\n",
    " - hence $\\bar{y} = \\hat{\\alpha} + \\hat{\\beta}\\bar{x}$ (so the line goes through the means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158e71a",
   "metadata": {},
   "source": [
    "### Video 18 - Deriving Least Squares Estimators - part 4\n",
    "\n",
    " - From the previous video we have $\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}$\n",
    " - Using the second equation we have $\\sum_{i=1}^Nx_iy_i = \\hat{\\alpha}\\sum_{i=1}^Nx_i + \\hat{\\beta} \\sum_{i=1}^Nx_i^2$\n",
    " - hence $\\sum_{i=1}^Nx_iy_i = \\hat{\\alpha}N\\bar{x} + \\hat{\\beta} \\sum_{i=1}^Nx_i^2$\n",
    " - subbing in $\\hat{\\alpha}$ we see  $\\sum_{i=1}^Nx_iy_i =(\\bar{y} - \\hat{\\beta}\\bar{x})N\\bar{x} + \\hat{\\beta} \\sum_{i=1}^Nx_i^2$\n",
    " - hence $\\sum_{i=1}^Nx_iy_i=\\bar{y}N\\bar{x} - \\hat{\\beta}\\bar{x}N\\bar{x} + \\hat{\\beta} \\sum_{i=1}^Nx_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff15fa",
   "metadata": {},
   "source": [
    "### Video 19 - Deriving Least Squares Estimators - part 5\n",
    "\n",
    " - From the last video $\\sum_{i=1}^Nx_iy_i=\\bar{y}N\\bar{x} - \\hat{\\beta}\\bar{x}N\\bar{x} + \\hat{\\beta} \\sum_{i=1}^Nx_i^2$\n",
    " - hence $\\sum_{i=1}^Nx_iy_i - \\bar{y}N\\bar{x} = \\hat{\\beta}(\\sum_{i=1}^Nx_i^2 - \\bar{x}N\\bar{x} )$\n",
    " - hence $\\hat{\\beta} = \\frac{\\sum_{i=1}^Nx_iy_i - \\bar{y}N\\bar{x}}{\\sum_{i=1}^Nx_i^2 - \\bar{x}N\\bar{x}}$\n",
    " - so $\\hat{\\beta} = \\frac{\\sum_{i=1}^N(x_i-\\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^N(x_i - \\bar{x})^2} = \\frac{Cov(x_i, y_i)}{Var(x_i)}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310dd1e",
   "metadata": {},
   "source": [
    "### Video 20 - Least squares estimators - in summary\n",
    "\n",
    " - Using sample to estimate relationships in the population.\n",
    " - In a wages vs education model the $\\hat{\\alpha}$ estimates the wages for someone with no education and $\\hat{\\beta}$ estimates the increase in wage for every extra year of education."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fe51f",
   "metadata": {},
   "source": [
    "### Video 21 - Taking the expectation of a random variable\n",
    "\n",
    " - A discrete random variable X takes an integer number of values $v_1, v_2, v_3,...,v_k$ with certain probabilities $p_1, p_2, p_3, ..., p_k$\n",
    " - We define the expectation $\\mathbb{E}[X] = \\sum_xP(X=x)x$\n",
    " - A continuous random variable Y takes a continuous range of values over some interval and has a probability distribution function $f_y$ defining the probability of all continuous values. \n",
    " - We define the expectation $\\mathbb{E}[X] = \\int_{-\\inf}^{\\inf}f_x(x)x\\,dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c1e54",
   "metadata": {},
   "source": [
    "### Video 22 - Moments of a random variable\n",
    "\n",
    " - We define the expectation of a random variable $\\mathbb{E}[X] = \\int_{-\\inf}^{\\inf}f_x(x)x\\,dx$\n",
    " - We define the expectation of $X^2$ as $\\mathbb{E}[X^2] = \\int_{-\\inf}^{\\inf}f_x(x)x^2\\,dx$. This is known as the second moment.\n",
    " - We define the kth moment of X as $\\mathbb{E}[X^k] = \\int_{-\\inf}^{\\inf}f_x(x)x^k\\,dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07731bb",
   "metadata": {},
   "source": [
    "### Video 23 - Central moments of a random variable\n",
    "\n",
    " - $\\mathbb{E}[(X-\\bar{X})^2]$ is known as the 2nd central moment or more commonly the variance. The variance tells us about as the shoulders of the distribution (the spread).\n",
    " - variance = 0 for a constant random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af86d5",
   "metadata": {},
   "source": [
    "### Video 24 - Kurtosis\n",
    "\n",
    " - $\\mathbb{E}[(X-\\bar{X})^4]$ is known as the 4th central moment.\n",
    " - The kurtosis is defined as the 4th standardised moment $Kurt[X] = \\mathbb{E}[(\\frac{X-\\bar{X}}{\\sigma})^4]$\n",
    " - The excess Kurtosis is defined as the kurtosis - 3 as the standard normal has kurtosis = 3. If the excess Kurtosis (sometimes just called Kurtosis) is negative that indicates thin tails and positive indicates fat tails.\n",
    " - The kurtosis helps to understand the tails of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644031b",
   "metadata": {},
   "source": [
    "### Video 25 - Skewness\n",
    "\n",
    " - Skewness is the standardised third central moment $\\mathbb{E}[(\\frac{X-\\bar{X}}{\\sigma})^3]$. A random variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd39e6",
   "metadata": {},
   "source": [
    "### Video 26 - Expectations and variance properties\n",
    "\n",
    " - $\\mathbb{E}[aX] = \\int_{-\\inf}^{\\inf}aXf_x(x)dx = a \\mathbb{E}[X]$\n",
    " - $Var(aX) = \\mathbb{E}[(aX - a \\bar{X})^2] = a^2 Var(X)$\n",
    " - $\\mathbb{E}[aX + bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]$\n",
    " - $\n",
    " Var(aX + bY) = \\mathbb{E}[(aX + bY - a \\bar{X} - b\\bar{y})^2]\\\\\n",
    "    = \\mathbb{E}[((aX - a\\bar{X}) + (bY - b\\bar{Y}))^2] \\\\\n",
    "    = \\mathbb{E}[(aX - a\\bar{X})^2] + \\mathbb{E}[(bY - b\\bar{Y})^2] + 2\\mathbb{E}[(aX - a\\bar{X})(bY - b\\bar{Y})]\\\\\n",
    "    = a^2 Var(X) + b^2Var(Y) + 2abCov(X,Y)\n",
    "   $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84d619",
   "metadata": {},
   "source": [
    "### Video n - zzzz\n",
    "\n",
    " - zzzzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbccac",
   "metadata": {},
   "source": [
    "### Video n - zzzz\n",
    "\n",
    " - zzzzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2b8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
